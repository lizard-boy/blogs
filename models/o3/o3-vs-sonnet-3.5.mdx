---

title: "Catch Me If You Can: Evaluating OpenAI: o3 vs Anthropic: Sonnet 3.5 in Bug Detection"
publishedAt: ''
author: ''
image: ''
summary: ''
keywords: ''
metaTitle: ''
metaDescription: ''
canonicalUrl: ''
category: 

---

Bug detection is a complex but crucial aspect of software development. As AI models evolve, their capabilities to identify issues in code before they hit production become increasingly vital. Recent developments have introduced reasoning models like Anthropic's Sonnet 3.5, which combines traditional LLM capabilities with a planning/thinking step, potentially offering enhanced bug detection. In this blog post, we'll compare OpenAI's o3 with Anthropic's Sonnet 3.5, assessing each model's ability to catch hard bugs within software programs.

## Results

In our tests, OpenAI o3 and Anthropic Sonnet 3.5 were evaluated across 210 bug samples, yielding varied results across different programming languages. Let's explore the outcomes.

### Overall Results

OpenAI o3 managed to catch a total of 38 out of 210 bugs, while Anthropic Sonnet 3.5 identified 26. 

### Language-Specific Results

- **Python:**
  OpenAI o3 detected 7 out of 42 bugs, while Anthropic Sonnet 3.5 found only 3. Python's widespread use means models are better trained on this language, possibly allowing simpler pattern matching without requiring deeper reasoning.

- **TypeScript:**
  OpenAI o3 again detected 7 of 42 bugs. Interestingly, Sonnet 3.5 detected 5, suggesting parity with a slight advantage for o3, likely due to the language's structured nature that might align with pattern detection.

- **Go:**
  Here, Anthropic Sonnet 3.5 identifying 8 of 42 bugs compared to OpenAI o3's 7.

- **Rust:**
  A challenging language but promising area for AI, Sonnet 3.5 detected 3 out of 41 bugs while OpenAI o3 detected 9. This result was unexpected, as Rust's complexity appeared to suit a reasoned approach.

- **Ruby:**
  Sonnet 3.5 caught 7 of 42 bugs, narrowly missing OpenAI o3's count of 8, cementing its advantage in parsing languages with less standardized syntax.

## Thoughts

The data suggests that Anthropic Sonnet 3.5's reasoning model, while generally leading in bug detection, offers more nuanced advantages in specific languages. Its comparative underperformance in Python and turnabout in Go and Ruby could be attributed to the varying dataset volumes available for different languages. Think-first models might require more unseen context variance that languages like Python naturally provide through training data.

Moreover, the results underline that not all code issues are equally detectable by planning models. Languages like Rust, where Sonnet underperformed, pose particular challenges potentially due to intricate syntactical complexities that evade pattern recognition without full contextual planning.

## Interesting Bugs

One notable instance was in test 19, concerning a **Data Partitioning Mechanism in Python**. The bug involved an incorrect allocation strategy using a random number generator rather than a genuine round-robin method. Interestingly, Anthropic Sonnet 3.5 flagged this oversight, but OpenAI o3 did not.

### Detailed Explanation:

**Anthropic Sonnet 3.5 reasoning output:**

> "The most critical bug is in the DataPartitioner's get_partition method where the ROUND_ROBIN strategy uses random.randint() instead of implementing a true round-robin distribution, which defeats the purpose of round-robin partitioning and could lead to uneven data distribution."

Sonnet 3.5, by planning its response, reasoned about the method's purpose and implementation context, catching an error based on logic flow rather than observable pattern.

## Conclusion

The nuanced analysis of OpenAI o3 versus Anthropic Sonnet 3.5 illustrates the potential utility of reasoning models in automated code review and bug detection. While the results varied, especially across programming languages, itâ€™s evident that the added reasoning step provides substantial improvements and highlights LLM's transformative potential in software verification.