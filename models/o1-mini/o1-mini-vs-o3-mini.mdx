---
title: 'AI Code Review: OpenAI o1-mini vs o3-mini for Bug Detection'
publishedAt: '2025-04-01'
author: 'Everett Butler'
image: '/model-vs/o1-mini-vs-o3-mini.png'
summary: 'We tested OpenAIâ€™s o1-mini and o3-mini models on their ability to detect subtle software bugs across Python, Go, TypeScript, Rust, and Ruby.'
keywords: 'ai code review, bug detection, openai o1-mini, openai o3-mini, reasoning models, software verification'
metaTitle: 'Bug Detection Benchmark: OpenAI o1-mini vs o3-mini | Greptile'
metaDescription: 'How do OpenAIâ€™s o1-mini and o3-mini compare when it comes to detecting real-world software bugs? We tested them on 210 hard bugs across five languages.'
canonicalUrl: 'https://www.greptile.com/blog/o1-mini-vs-o3-mini'
category: tools
---

AI models are getting better at writing code â€” but can they review it? In this post, we compare two small models from OpenAI: **o1-mini** and **o3-mini**, evaluating their ability to catch **real-world bugs** in code.

Bug detection requires more than just syntax knowledge â€” it demands logic, context, and inference. Letâ€™s see which model performs better.


## ðŸ§ª The Evaluation Dataset

I wanted to have the dataset of bugs to cover multiple domains and languages. I picked sixteen domains, picked 2-3 self-contained programs for each domain, and used Cursor to generate each program in TypeScript, Ruby, Python, Go, and Rust.

Here are the programs we created for the evaluation:

<table
	style={{
		borderCollapse: 'collapse',
		width: '100%',
		margin: '2rem 0',
		borderRadius: '8px',
		overflow: 'hidden',
		fontSize: '0.95rem',
		lineHeight: '1.5'
	}}>
	<thead>
		<tr>
			<th
				style={{
					backgroundColor: '#f8fafc',
					padding: '1rem',
					textAlign: 'left',
					borderBottom: '1px solid #e2e8f0',
					fontWeight: '600',
					color: '#1a202c'
				}}>
				ID
			</th>
			<th
				style={{
					backgroundColor: '#f8fafc',
					padding: '1rem',
					textAlign: 'left',
					borderBottom: '1px solid #e2e8f0',
					fontWeight: '600',
					color: '#1a202c'
				}}></th>
		</tr>
	</thead>
	<tbody>
		{[
			['1', 'distributed microservices platform'],
			['2', 'event-driven simulation engine'],
			['3', 'containerized development environment manager'],
			['4', 'natural language processing toolkit'],
			['5', 'predictive anomaly detection system'],
			['6', 'decentralized voting platform'],
			['7', 'smart contract development framework'],
			['8', 'custom peer-to-peer network protocol'],
			['9', 'real-time collaboration platform'],
			['10', 'progressive web app framework'],
			['11', 'webassembly compiler and runtime'],
			['12', 'serverless orchestration platform'],
			['13', 'procedural world generation engine'],
			['14', 'ai-powered game testing framework'],
			['15', 'multiplayer game networking engine'],
			['16', 'big data processing framework'],
			['17', 'real-time data visualization platform'],
			['18', 'machine learning model monitoring system'],
			['19', 'advanced encryption toolkit'],
			['20', 'penetration testing automation framework'],
			['21', 'iot device management platform'],
			['22', 'edge computing framework'],
			['23', 'smart home automation system'],
			['24', 'quantum computing simulation environment'],
			['25', 'bioinformatics analysis toolkit'],
			['26', 'climate modeling and simulation platform'],
			['27', 'advanced code generation ai'],
			['28', 'automated code refactoring tool'],
			['29', 'comprehensive developer productivity suite'],
			['30', 'algorithmic trading platform'],
			['31', 'blockchain-based supply chain tracker'],
			['32', 'personal finance management ai'],
			['33', 'advanced audio processing library'],
			['34', 'immersive virtual reality development framework'],
			['35', 'serverless computing optimizer'],
			['36', 'distributed machine learning training framework'],
			['37', 'robotic process automation rpa platform'],
			['38', 'adaptive learning management system'],
			['39', 'interactive coding education platform'],
			['40', 'language learning ai tutor'],
			['41', 'comprehensive personal assistant framework'],
			['42', 'multiplayer collaboration platform']
		].map((row, i) => (
			<tr
				key={i}
				style={{
					backgroundColor: 'var(--tw-prose-bg, white)',
					transition: 'background-color 0.2s'
				}}>
				<td
					style={{
						padding: '1rem',
						borderBottom: '1px solid var(--tw-prose-border, #e2e8f0)',
						color: 'var(--tw-prose-body, #1a202c)'
					}}>
					{row[0]}
				</td>
				<td
					style={{
						padding: '1rem',
						borderBottom: '1px solid var(--tw-prose-border, #e2e8f0)',
						color: 'var(--tw-prose-body, #1a202c)'
					}}>
					{row[1]}
				</td>
			</tr>
		))}
	</tbody>
</table>

Next I cycled through and introduced a tiny bug in each one. The type of bug I chose to introduce had to be:

1. A bug that a professional developer could reasonably introduce
2. A bug that could easily slip through linters, tests, and manual code review

Some examples of bugs I introduced:

1. Undefined \response\ variable in the ensure block
2. Not accounting for amplitude normalization when computing wave stretching on a sound sample
3. Hard coded date which would be accurate in most, but not all situations

At the end of this, I had 210 programs, each with a small, difficult-to-catch, and realistic bug.

A disclaimer: these bugs are the hardest-to-catch bugs I could think of, and are not representative of the median bugs usually found in everyday software.

## ðŸ“Š Results

**Overall Bugs Caught**
- **OpenAI o1-mini**: 11 bugs  
- **OpenAI o3-mini**: 37 bugs

Thatâ€™s more than a **3Ã— improvement** from o1 to o3 â€” a significant step forward.

**By Language**
- **Python**: o1-mini 2, o3-mini 7  
- **TypeScript**: o1-mini 1, o3-mini 7  
- **Go**: o1-mini 2, o3-mini 7  
- **Rust**: o1-mini 2, o3-mini 9  
- **Ruby**: o1-mini 4, o3-mini 7

o3-mini outperformed o1-mini across **every language**, often by a wide margin.

## ðŸ§  Interpretation

The performance gap reflects more than just scale â€” it highlights an architectural shift.

- **o1-mini** is lightweight, likely optimized for speed and simple pattern recognition.
- **o3-mini** appears to integrate **structured reasoning**, allowing it to follow logic chains, infer intent, and detect subtle issues in concurrency and flow.

Thatâ€™s why o3-mini shines in languages like Rust and Go â€” where reasoning about ownership, memory, or parallelism is key. It also performs better in TypeScript and Python, likely due to improved training data coverage and planning capability.

## ðŸ§© A Bug Worth Highlighting

### Go â€” Race Condition in NotifyDeviceUpdate

In a smart home backend, device state updates were being sent without proper synchronization, resulting in race conditions.

- **o1-mini** missed the issue  
- **o3-mini** correctly identified the lack of locking

o3-miniâ€™s output:
> "There is no locking around device updates before broadcasting, which could lead to race conditions where clients receive stale or partially updated device state."

This wasnâ€™t a syntax error â€” it was a **concurrency flaw** that required simulating how code might behave under load. Thatâ€™s where reasoning-first models thrive.

## âœ… Final Thoughts

This benchmark makes the case clear: **o3-mini is significantly better than o1-mini at detecting subtle software bugs**. It handles logical reasoning, concurrency, and intent much more effectively.

- Use **o3-mini** if you want a compact model that still offers strong reasoning.
- Use **o1-mini** if you need a small, fast model and are OK with lower bug coverage.

---
Greptile uses models like o3-mini in production to catch bugs in pull requests â€” before they reach production. Want to try it on your repo? [Try Greptile](https://www.greptile.com) â€” no credit card required.
